# 实验设计部分

首先需要了解实验室的，单机多卡实验环境，pci对应端口的实际传输速率，

在数据庞大的时候，需要使用batchsize

实验室使用的Tensorflow版本



总样本数/batchsize=iter

总的迭代次数=iter*epoch



### 实验一：卷积神经网络计算量测试

1.首先需要先选出计算用的模型

2.分析模型的参数量，模型层数，模型的实际计算量（实际情况分析）

3.通过基本数据，估算总计算量结果，进行验证

### 实验二：测试GPU计算力与$W_{iter}$的拟合关系

如果对于一个GPU进行计算来说的话，设置不同的batchsize，对于GPU计算量来说应该同样是满足的

实验观察来说，在batchsize较小的情况下，显存的占用量并无变化（1500MB左右），另外在每一次epoch计算完之后，会存在短暂CPU占用量立即升高的情况,GUP利用率在一般情况下只有50%

有关于计算量的：一张图片对应的是一个总计算量，但是对于总参数量来说，是不变的

对于模型来说，一共是60000张训练集和10000张测试集

|   模型名称   | 总计算量(GMac) | 总参数量(M) | 估计参数量 |      |
| :----------: | :------------: | :---------: | :--------: | ---- |
|   AlexNet    |      0.71      |    61.1     |    0.71    |      |
|    VGG16     |      15.5      |   138.36    |            |      |
| Densenet121  |      2.88      |    7.98     |            |      |
|   ResNet50   |      4.12      |    25.56    |            |      |
|   ResNet18   |      1.82      |    11.69    |            |      |
| Inception_v3 |      2.85      |    27.16    |            |      |
|  Googlenet   |      1.51      |     6.6     |            |      |
|              |                |             |            |      |

计算使用：Alexnet = 0.71*6000Gmac

| Batchsize | AlexNet | ResNet18 | VGG16 | 力   |
| :-------: | :-----: | :------: | :---: | ---- |
|   1024    |         |          |       |      |
|    512    |  15.5   |   15.5   |       |      |
|    256    |  16.7   |   16.3   |       |      |
|    128    |  17.7   |   18.2   | 42.3  |      |
|    64     |  20.8   |   21.9   | 46.2  |      |
|    32     |  25.8   |   29.5   | 58.0  |      |
|    16     |  40.0   |   46.4   | 83.8  |      |
|     8     |  73.4   |   92.0   | 125.7 |      |
|     4     |  133.4  |  179.8   | 193.1 |      |
|     2     |  259.6  |  359.0   | 348.2 |      |
|     1     |  507.7  |  718.9   | 635.7 |      |



数据集选择







---

## 综合实验测试

测试用例

（是否需要对不同类型的机器学习模型进行考虑）

![image-20210316162919930](/Users/xiangxiangyongan/Library/Application Support/typora-user-images/image-20210316162919930.png)

VGG16,ALexnet,ResNet50(如果只用CNN模型会怎么样)



---

平均 GPU 利用率仅为 52％左右

压力测试

对于任务到来的密度进行修改，不断查看总消耗时间



有待测试算法：

李雅普诺夫优化算法

基于FIFO的单GPU分配算法

基于FIFO的多GPU分配算法

基于最短任务的单GPU分配算法

优先级调度



目的是获得长时间中，任务的总花费时间最短，或是检测任务在集群中的存在时间







https://youtube.com/playlist?list=PLqybz7NWybwUgR-S6m78tfd-lV4sBvGFG

